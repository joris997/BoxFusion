dataset: online
model_path: ./models/cutr_rgbd.pth
clip_path: ./models/open_clip_pytorch_model.bin
class_features: './data/class_features.pt'
class_txt: ./data/panoptic_categories_nomerge.txt
viz_on_gt_points: True
device: cuda
total_duration: 5

data:
  datadir: ~/c_space_stl_results/BoxFusion/
  start: 0 
  output_dir: ./results
  gap: 25


# cam:
#   H: 480
#   W: 640
#   fx: 320.0
#   fy: 320.0
#   cx: 319.5
#   cy: 239.5
#   png_depth_scale: 1000.
# cam:
#   H: 480
#   W: 640
#   fx: 607.2999
#   fy: 607.3384
#   cx: 319.2763
#   cy: 235.4929
#   png_depth_scale: 1000

# Azure Kinect DK
rgb_cam: # scaled from 2048x1536
  H: 480
  W: 640
  fx: 303.2797
  fy: 303.1887
  cx: 315.6464
  cy: 242.3771
depth_cam: # scaled from 1024x1024
  H: 480
  W: 640
  # fx: 315.85
  # fy: 236.74
  # cx: 320.25
  # cy: 240.53
  fx: 303.2797
  fy: 303.1887
  cx: 315.6464
  cy: 242.3771
  png_depth_scale: 1000.0

detection:
  score_thresh: 0.4 #0.4 #0.25
  uv_bound: True
  uv_bound_value: 0.9
  floor_mask: True #False
  floor_ratio: 15
  scale_box: 0.9
  workspace_filter: True
  workspace:
    x: [0.0, 1.25]
    y: [-0.5, 0.5]
    z: [0.0, 1.0]

association:
  small_threshold: 0.1 #0.2
  rotation_gap: 30 #30
  translation_gap: 0.8 #1.0 #0.8 #0.5 #0.5 best #1.0 #0.1


box_fusion:
  use: True 
  iters: 20 
  pst_path: ./data/pst_1024_0.tiff
  pst_size: 1024
  random_opt:
    center_init_size: 0.1 
    center_scaling_coefficient:  0.1
    shape_init_size: 0.5
    shape_scaling_coefficient: 0.5 
  check_valid: False
  nms_threshold: 0.1 
  small_size: 0.35


vis:
  rerun: True
  show_class: True 
  show_label: True 
  trajectory: True

eval: False